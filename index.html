<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="description" content="DualReal: Adaptive Joint Training for Lossless Identity-Motion Fusion in Video Customization">
  <!-- 简化社交媒体元信息 -->
  <meta property="og:title" content="DualReal: Video Customization Framework"/>
  <meta property="og:description" content="Achieving identity-motion fusion through adaptive joint training"/>
  <meta property="og:image" content="<image-banner-social>">

  <meta name="twitter:card" content="summary_large_image">
  <meta name="keywords" content="video generation, deep learning, identity preservation">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>DualReal</title>
  
  <!-- 简化样式表 -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.9.4/css/bulma.min.css">

  <style>
    /* 参考网站基础样式 */
    body {
      font-family: 'Georgia', serif;
      line-height: 1.6;
      color: #333;
    }
    
    .section {
      padding: 4rem 1.5rem;
    }
    
    .title {
      font-weight: 600;
      margin-bottom: 1.5rem;
    }
    
    .paper-title {
      font-size: 2.2rem;
      line-height: 1.2;
      margin-bottom: 1.2rem;
    }

    .author-list {
      font-size: 1.1rem;
      margin: 1.5rem 0;
    }

    .content-block {
      max-width: 800px;
      margin: 0 auto;
    }

    .video-container {
      position: relative;
      padding-bottom: 56.25%;
      margin: 2rem 0;
    }

    .video-container iframe {
      position: absolute;
      width: 100%;
      height: 100%;
    }

    /* 修改图片容器样式 */
    .teaser-image {
        margin: 4rem auto 3rem;  /* 增加上下边距 */
        max-width: 1400px;      /* 增大最大宽度 */
        padding: 0 2rem;        /* 增加水平内边距 */
    }

    .teaser-image img {
        width: 100%;           /* 保持响应式宽度 */
        height: auto;          /* 保持原始比例 */
        border-radius: 6px;    /* 增大圆角半径 */
    }

    /* 图片说明文字调整 */
    .teaser-image p {
        font-size: 1.1rem;     /* 增大字体 */
        margin-top: 1.5rem;     /* 增加间距 */
    }
    
    /* 视频容器样式 */
    .slides-container {
        width: 100%;
        overflow: hidden;  /* 仅容器内部隐藏溢出 */
        display: flex;
        transition: transform 0.5s ease-in-out;
    }

    .slider-button {
        position: absolute;
        top: 50%;
        transform: translateY(-50%);
        background: rgba(255,255,255,0.9);
        width: 40px;
        height: 40px;
        border-radius: 50%;
        display: flex;
        align-items: center;
        justify-content: center;
        box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        border: 1px solid rgba(0,0,0,0.1);
        z-index: 10;
        cursor: pointer;
        transition: all 0.3s ease;
    }

    .slider-button:hover {
        border-color: #3b82f6; /* 品牌蓝色 */
        color: #3b82f6;
        transform: translateY(-50%) scale(1.1);
        box-shadow: 0 4px 12px rgba(59, 130, 246, 0.1);
    }

    .slider-button:active {
        transform: translateY(-50%) scale(0.95);
    }


    .prev { left: 20px; }
    .next { right: 20px; }

    .video-section {
        position: relative;
        padding: 4rem 0; /* 保持与Bulma的section一致 */
        background: #f8f9fa; /* 可选背景色 */
    }

    .video-slider {
        position: relative;
        max-width: 650px;
        margin: 0 auto; /* 居中 */
        /*verflow: visible; */
        border-radius: 12px; /* 可选圆角 */
        box-shadow: 0 10px 20px rgba(0,0,0,0.1); /* 可选阴影 */
        padding: 0 40px;
    }

    .video-slide {
        display: flex;
        flex: 0 0 100%; /* 每个slide占满容器宽度 */
        min-width: 100%;
        box-sizing: border-box;
        justify-content: center;
        align-items: center;
        transition: transform 0.5s; 
    }

    /* 视频元素样式 */
    video {
        width: 80%;
        height: auto;
        max-height: 400px;
        border-radius: 8px;
    }
        
    /* 响应式调整 */
    @media (max-width: 768px) {
        .slider-button {
            width: 30px;
            height: 30px;
            border-width: 1.5px;
        }
        
        .prev {
            left: -10px;
        }
        
        .next {
            right: -10px;
        }
    }

    @media screen and (max-width: 768px) {
        .teaser-image {
        margin: 3rem auto;
        padding: 0 1.5rem;
        }
        
        .teaser-image img {
        border-radius: 4px;
        }

        .teaser-image p {
        font-size: 1rem;
        padding: 0 1rem;
        }
    }

    @media screen and (min-width: 1600px) {
        .teaser-image {
        max-width: 90vw;     /* 在超大屏幕上使用视口单位 */
        }
    }

    @media (max-width: 768px) {
      .prev { left: -30px; }
      .next { right: -30px; }
    }

  </style>
</head>

<body>
  <!-- 简化Header部分 -->
  <section class="section">
    <div class="content-block">
      <h1 class="title paper-title has-text-centered">
        DualReal: Adaptive Joint Training for<br>Lossless Identity-Motion Fusion
      </h1>
      
      <div class="author-list has-text-centered">
        <span>
          <a href="mailto:wenc_k@mail.ustc.edu.cn" target="_blank">Wenchuan Wang</a>,
        </span>
        <span>
          <a href="mailto:huangmq@mail.ustc.edu.cn" target="_blank">Mengqi Huang</a>,
        </span>
        <span>
          <a href="mailto:tuyijing@mail.ustc.edu.cn" target="_blank">Yijing Tu</a>,
        </span>
        <span>
          <a href="mailto:zdmao@ustc.edu.cn" target="_blank">Zhendong Mao</a><sup>*</sup>
        </span>
        <div class="institution mt-2">
          University of Science and Technology of China,
        </div>
        <div class="institution mt-2">
          <sup>*</sup>Corresponding author
        </div>
      </div>

      <!-- 简化按钮 -->
      <div class="buttons is-centered are-medium">
        <a href="#paper" class="button is-rounded">
          <span class="icon"><i class="fas fa-file-pdf"></i></span>
          <span>Paper</span>
        </a>
        <a href="#code" class="button is-rounded is-dark">
          <span class="icon"><i class="fab fa-github"></i></span>
          <span>Code(coming soon)</span>
        </a>
      </div>

      <!-- 新增展示图区块 -->
      <div class="teaser-image" style="margin: 3rem auto 2rem; max-width: 1200px;">
        <img src="./img/result.png" 
             alt="DualReal Result Showcase"
             style="width: 100%; 
                    height: auto;
                    border-radius: 4px;">
        <p>
          Generated customization results of our proposed novel paradigm DualReal. Given subject images and motion videos, DualReal generates high-quality customized identity and motion simultaneously, without compromising the consistency of either dimension.
        </p>
      </div>
    </div>
  </section>

  <!-- 摘要部分 -->
  <section class="section" style="background: #f8f9fa;">
    <div class="content-block">
      <h2 class="title is-3 has-text-centered">Abstract</h2>
      <div class="content">
        <p>
            Customized text-to-video generation with pre-trained large-scale models has recently garnered significant attention through focusing on identity and motion consistency. Existing works typically follow the isolated customized paradigm, where the subject identity or motion dynamics are customized exclusively. However, this paradigm completely ignores the intrinsic mutual constraints and synergistic interdependencies between identity and motion, resulting in identity-motion conflicts throughout the generation process that systematically degrades. To address this, we introduce DualReal, a novel framework that, employs adaptive joint training to collaboratively construct interdependencies between dimensions. Specifically, DualReal is composed of two units: (1) Dual-aware Adaptation dynamically selects a training phase (i.e., identity or motion), learns the current information guided by the frozen dimension prior, and employs a regularization strategy to avoid knowledge leakage; (2) StageBlender Controller leverages the denoising stages and Diffusion Transformer depths to guide different dimensions with adaptive granularity, avoiding conflicts at various stages and ultimately achieving lossless fusion of identity and motion patterns. We constructed a more comprehensive evaluation benchmark than existing methods. The experimental results show that DualReal improves CLIP-I and DINO-I metrics by 21.7% and 31.8% on average, and achieves top performance on nearly all motion quality metrics.
        </p>
      </div>
    </div>
  </section>

  <!-- 方法图示 -->
  <section class="section">
    <div class="content-block">
      <h2 class="title is-3 has-text-centered">How does it work?</h2>
      <div class="has-text-centered">
        <img src="./img/pipeline.png" 
        alt="DualReal Pipeline"
        style="width: 100%; 
                height: auto;
                border-radius: 4px;">
      </div>
      <div class="content mt-4">
        <p> 
            <b>Training Paradigm:</b> At each training step, we first dynamically select the training phase Z(i.e., identity or motion) to determine the data processing path. The specific data undergoes noise injection and combines with the text embeddings. StageBlender Controller governs two-dimension adapters' contributions in Dual-Aware Block (DA-Block) through time-aware conditioning of current denoising step and fused feature representations. In DA-Block, the training-stage(Z) adapter learns the current information guided by the frozen dimension prior, and employs a regularization strategy to avoid dimensional knowledge leakage, achieving joint training. Both branches engage in residual connections with DiT outputs.  
        </p>
      </div>
      <div class="has-text-centered">
        <img src="./img/pipeline-2.png" 
        alt="DualReal Pipeline"
        style="width: 60%; 
                height: auto;
                border-radius: 4px;">
      </div>
      <div class="content mt-4">
        <p> 
            <b>StageBlender Controller</b> employs Adaptive LayerNorm mechanism  modulates text-visual feature based on timestep-conditional embeddings, then maps the feature to multiple groups after residual gated connections. These scaled weight are subsequently routed to their respective DA-Blocks for processing.
        </p>
      </div>
    </div>
  </section>

  <!-- 对比结果 -->
  <section class="section">
    <div class="content-block">
      <h2 class="title is-3 has-text-centered">Comparison Results</h2>
      <div class="has-text-centered">
        <img src="./img/mainresult.png" 
        alt="DualReal Pipeline"
        style="width: 100%; 
                height: auto;
                border-radius: 4px;">
      </div>
      <div class="content mt-4">
        <p> 
            <b>Qualitative comparison with existing methods.</b> Compared with other methods, DualReal achieves high identity consistency with coherent motion, demonstrating the advantage of joint training in balancing pattern conflicts.
        </p>
      </div>

      <div class="has-text-centered">
        <img src="./img/exp_png.png" 
        alt="DualReal Pipeline"
        style="width: 100%; 
                height: auto;
                border-radius: 4px;">
      </div>
      <div class="content mt-4">
        <p> 
          <b>Quantitative comparison of personalization video generation for customized subject and motion.</b> "T.Cons" and "T.Flickering" denotes Temporal Consistency and Temporal Flickering, respectively. Compared with other methods, DualReal achieved average improvements of <b>21.7%</b> on CLIP-I and <b>31.8%</b> on DINO-I, recorded the best results on three motion quality metrics (T.Cons, Motion Smoothness, and Temporal Flickering), and ranked second on CLIP-T. The motion datasets achieve an average Dynamic Degree of <b>12.02</b> and parenthetical values quantify the current method’s deviation from this benchmark to determine the intensity consistency of movement.
        </p>
      </div>
    </div>
  </section>

  <!-- 轮播容器改为 section -->
  <section class="section video-section" style="background: #f8f9fa;">
    <div class="container">
        <h2 class="title is-3 has-text-centered">More Results</h2>
        <!-- 视频容器保留原有结构 -->
        <div class="video-slider">
            <div class="slides-container" id="slidesContainer">
                <!-- 视频项保持不变 -->
                <div class="video-slide">
                    <video controls>
                        <source src="videos/case3.mp4" type="video/mp4">
                    </video>
                </div>
                <div class="video-slide">
                  <video controls>
                      <source src="videos/case5.mp4" type="video/mp4">
                  </video>
                </div>
                <div class="video-slide">
                  <video controls>
                      <source src="videos/case8.mp4" type="video/mp4">
                  </video>
                </div>
                <div class="video-slide">
                  <video controls>
                      <source src="videos/case12.mp4" type="video/mp4">
                  </video>
                </div>
                <div class="video-slide">
                  <video controls>
                      <source src="videos/case13.mp4" type="video/mp4">
                  </video>
                </div>
            </div>
            <!-- 导航按钮 -->
            <button class="slider-button prev">
              <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                  <path stroke-linecap="round" stroke-linejoin="round" d="M15 19l-7-7 7-7"/>
              </svg>
            </button>

            <button class="slider-button next">
              <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                  <path stroke-linecap="round" stroke-linejoin="round" d="M9 5l7 7-7 7"/>
              </svg>
            </button>
        </div>
    </div>
  </section>

<!--
  <section class="section" style="background: #f8f9fa;">
    <div class="content-block">
      <h2 class="title is-3 has-text-centered">More Results</h2>
      <div class="video-container">
        <iframe src="https://www.youtube.com/embed/<video-youtube-id>" frameborder="0" allowfullscreen></iframe>
      </div>
    </div>
  </section>


  <section class="section" style="background: #f8f9fa;">
    <div class="content-block">
      <h2 class="title is-3 has-text-centered">Citation</h2>
      <pre style="background: #fff; padding: 1.5rem; border-radius: 4px;"><code>@article{dualreal2024,
  title={DualReal: Adaptive Joint Training for Lossless Identity-Motion Fusion},
  author={Wang, Wenchuan and Huang, Mengqi and Tu, Yijing and Mao, Zhendong},
  journal={arXiv preprint arXiv:XXXX.XXXXX},
  year={2024}
}</code></pre>
    </div>
  </section>
-->

  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
  
            <p>
              This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
              You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
              Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>
  
          </div>
        </div>
      </div>
    </div>
  </footer>

  <!-- 基础脚本 -->
  <script defer src="https://use.fontawesome.com/releases/v5.3.1/js/all.js"></script>
  <script>
  document.addEventListener('DOMContentLoaded', () => {
      const slidesContainer = document.querySelector('#slidesContainer');
      const slides = document.querySelectorAll('.video-slide');
      const prevButton = document.querySelector('.prev');
      const nextButton = document.querySelector('.next');
      let currentIndex = 0;
  
      // 正确计算slide宽度（包含padding和border）
      const getSlideWidth = () => {
          const slideStyle = window.getComputedStyle(slides[0]);
          return slides[0].offsetWidth + 
                  parseInt(slideStyle.marginLeft) + 
                  parseInt(slideStyle.marginRight);
      };
  
      // 初始化容器宽度
      const initSlider = () => {
          const slideWidth = getSlideWidth();
          slidesContainer.style.width = `${slideWidth * slides.length}px`;
      };
  
      // 更新轮播位置
      const updatePosition = () => {
          slidesContainer.style.transform = `translateX(-${currentIndex * 100}%)`;
      };
  
      // 事件处理
      prevButton.addEventListener('click', () => {
          if (currentIndex > 0) {
              currentIndex--;
              updatePosition();
          }
      });
  
      nextButton.addEventListener('click', () => {
          if (currentIndex < slides.length - 1) {
              currentIndex++;
              updatePosition();
          }
      });
  
      // 初始化及窗口调整
      initSlider();
      window.addEventListener('resize', initSlider);
  });
  </script>
</body>
</html>